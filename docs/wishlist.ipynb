{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Camille Avestruz (UChicago)_, _Alex Malz (NYU)_, _Tom McClintock (SBU)_, _Mariana Penna Lima (IN2P3)_ & Others\n",
    "\n",
    "This is a wishlist for how we'd like to use `clmassmod`.  We will refactor the code to make this notebook run!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our understanding of how folks currently use this code is based in part on the [Analytic Bias Estimate (ABE)](https://github.com/LSSTDESC/clmassmod/blob/master/notebooks/Analytic_bias_estimate.ipynb) and [Statistical Power Check (SPC)](https://github.com/LSSTDESC/clmassmod/blob/master/notebooks/Statistical%20Power%20Check.ipynb) demos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# . . .\n",
    "import clmassmod as clmm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This could be done internally to `clmassmod` or externally by a user-defined function, but one way or another the user will need to read in parameters from a config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_info = clm.utils.load_config(config_file_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`model_info` would be a dict with the name of the model and its parameters to support comparison of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "massmod = clm.CLMassMod(model_info)\n",
    "# NumCosmo may have some of these already as NcDensityProfile class (NcDensityProfileNFW, Einasto, Diemer & Kravtsov, user-defined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `CLMassMod` object should be able to perform fitting based on any combination of a variety of lensing observables, not just a mass map.  We can transform those observations into a standard format or ask the user to do that.\n",
    "\n",
    "If the user wants to perform a stacked fit, the following two cells should be repeated in a loop over all of the relevant clusters, or the massmod object itself should contain the functionality to read in multiple maps at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_data_mass_map = clm.utils.load_mass_map(mass_map_loc)\n",
    "in_data_kappa_map = clm.utils.load_kappa_map(kappa_map_loc)\n",
    "in_data_gamma_theta = clm.utils.load_gamma_theta(gamma_theta_loc)\n",
    "in_data_delta_sigma = clm.utils.load_delta_sigma(delta_sigma_loc)\n",
    "\n",
    "massmod.obs_mass_map = in_data_mass_map\n",
    "massmod.obs_kappa_map = in_data_kappa_map\n",
    "massmod.obs_gamma_theta = in_data_gamma_theta\n",
    "massmod.obs_delta_sigma = in_data_delta_sigma\n",
    "# NumCosmo has the NcWLSurfaceMassDensity/NcWeakLensing/NcDensityProfile/NcHICosmo class, the maps could be instances of that class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reading in the maps from simulations, a lensed galaxy catalog must be produced by sampling from the maps, adding in shape and measurement noise, then converting it to a shear profile. This will serve as the input mock WL observations. It should probably take place under the hood of the massmod object. This will occur for both individual fits and stacking fits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most basic functionality of `clmassmod` should be to fit cluster masses, saving data incrimentally as insurance against computational instability.\n",
    "\n",
    "`calc_method` is a string keyword for curvefit vs. pymc vs. whatever, could be parallelized\n",
    "\n",
    "`calc_params` is a dict of parameters necessary for the specified fitting method\n",
    "\n",
    "`save_loc` should be the path to which output is saved, one file per halo\n",
    "\n",
    "`fit_info` is the object produced by the fitter, like the pymc MC object, with properties like diagnostics already in it\n",
    "\n",
    "`out_data_profiles` is pdfs or mles over cluster mass and metadata, preferably as a set of (named) tuples\n",
    "\n",
    "Extra stack parameters:\n",
    "`method` can be either \"woScaling\" for stacking without scaling, or \"wScaling\" for stacking with scaling.\n",
    "\n",
    "`presetX` is the user-defined binning for either the radial distance (for stacking without scaling) or for the scaled distance parameter x=r/rs (for stacking with scaling). It defines the bins that will help determine the eventual weighted radial bins for the stack.\n",
    "\n",
    "If one wants to perform the fit on a stack of clusters rather than on individual clusters, the following form should remain roughly the same. The only difference would be that either we will have an instance of `massmod` for each cluster, or a single instance of `massmod` which contains the shear profiles from all the clusters in the stack (probably better). Then the stack+fit process can be under the hood in a set of stacking tools accessed by the `massmod` object. The intermediate step on the front end then could be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "non-keyword arg after keyword arg (<ipython-input-3-25bb2f5fc176>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-25bb2f5fc176>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    massmod.deltaSigma, massmod.errSigma, massmod.avgR = massmod.stackTools.stack(method='woScaling', presetX)\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m non-keyword arg after keyword arg\n"
     ]
    }
   ],
   "source": [
    "#for stacking without scaling (more common method). There's probably a saner way to write this. I just want the stacked\n",
    "#profile (deltaSigma) to be saved to the massmod object.\n",
    "massmod.deltaSigma, massmod.errSigma, massmod.avgR = massmod.stackTools.stack(method='woScaling', presetX)\n",
    "\n",
    "#for stacking with scaling (from Niikura et al (2015)). When stacking with scaling, you don't actually fit a profile\n",
    "#to the stack, you just see how close the average form of the profiles are to NFW\n",
    "massmod.F, massmod.errF, massmod.avgX = massmod.stackTools.stack(method='wScaling', presetX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_data_profiles, fit_info = massmod.fit_mass_profiles(calc_method, calc_params, save_loc)\n",
    "# NumCosmo may do this already as NcmFit/NcmM-SetCatalog, also supports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`clmassmod` should be able to calculate statistics on these results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NumCosmo may do this already as NcmDataVoigt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Progress should be saved incrimentally, but the user should also be able to save it manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "massmod.save_mass_profiles(save_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If binning is desirable, the user should provide a scheme for assigning clusters to bins, which would be a function outside of `clmassmod`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bin_defs = np.linspace(bin_min, bin_max, n_bins)\n",
    "\n",
    "def bin_one_func(out_data_profile):\n",
    "# Consider a user-defined function that takes a mass profile and assigns a bin \n",
    "# based on a list or array containing bin endpoints.\n",
    "#     ...\n",
    "    return(bin_id)\n",
    "\n",
    "def bin_all_func(mass_profiles):\n",
    "# Consider a user-defined function that takes all the mass profiles provides a list of lists (one per bin) \n",
    "# of where they can be found based on their save locations\n",
    "#     ...\n",
    "    bin_member_locs = [] * len(bin_defs)\n",
    "    for one__profile in mass_profiles:\n",
    "        bin_id = bin_one_func(bin_defs, fluster_profile)\n",
    "        halo_loc = one__profile.loc\n",
    "        bin_members[bin_id].append(halo_loc)\n",
    "#     ...\n",
    "    return(bin_member_locs)\n",
    "\n",
    "bin_member_locs = clm.utils.make_bins(out_data_profiles, bin_all_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `clmassmod` object could then be instantiated for each bin.  Let's consider the following cells being run independently on each bin, say, in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bin_massmod = clm.CLMassMod(model_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the individual profile fits, so this can be done totally independently, i.e. in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bin_mass_profile_data = bin_massmod.read(bin_loc)\n",
    "clust_mass_dist = bin_massmod.ensemble_fit(calc_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can find the probability distribution over mass bias!\n",
    "\n",
    "`truth` is the masses from simulations in some as yet unspecified format, which should not be required for any steps before this, so they can be run on real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "likelihoods, posteriors, mass_dist_bias_samps, mass_dist_scatter_samps = bin_massmod.compare(truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This demo must run on a simulated catalog for validation to be complete, with precision checks at each step, ultimately including baryonic effects and with different mass profile parametrizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
